import math
from statistics import mean
class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left, lower, right, upper : int
        An int describing the position of the (left/lower/right/upper) border of the crop's bounding box in the original image.
    confidence: float 
        A float between 0 and 1 describing how likely the specific object is in the image 
    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the
        image matching the object_name.
    exists(object_name: str)->float
        Returns probability object specified by object_name is in image  
    verify_property(property: str)->float
        Returns probability property is met 
    best_text_match(option_list: List[str], prefix: str, confidence: float)->str
        Returns the string that best matches the image with confidence 
    compute_depth()->float
        Returns the median depth of the image crop.
    crop(left: int, lower: int, right: int, upper: int,confidence: float)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates and probability of object existing in crop
    """

    def __init__(self, image, left: int = None, lower: int = None, right: int = None, upper: int = None, confidence: float = None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as
        attributes. If no coordinates are provided, the image is left unmodified, and the coordinates are set to the
        dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left, lower, right, upper : int
            An int describing the position of the (left/lower/right/upper) border of the crop's bounding box in the original image.
       confidence: float   
            Probability object is contained in bounding box 
        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
            self.confidence = 1.0
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower
            self.confidence = confidence 

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str) -> List[ImagePatch]:
        """Returns a list of ImagePatch objects matching object_name contained in the crop if any are found.
        Otherwise, returns an empty list.
        Parameters
        ----------
        object_name : str
            the name of the object to be found

        Returns
        -------
        List[ImagePatch]
            a list of ImagePatch objects matching object_name contained in the crop

        Examples
        --------
        >>> # return the foo
        >>> def execute_command(image) -> List[ImagePatch]:
        >>>     confidences = []
        >>>     image_patch = ImagePatch(image)
        >>>     foo_patches = image_patch.find("foo")
        >>>     for f in foo_patches:
        >>>         confidences.append(f.confidence)
        >>>     return sum_tensor(confidences)
        """
        return find_in_image(self.cropped_image, object_name)

    def exists(self, object_name: str) -> bool:
        """Returns probability of object specified by object_name being found in the image.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        Returns 
        -------
        float 
            Float is probability of object existing 
        Examples
        -------
        >>> # How likely are there both foos and garply bars in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_foo = image_patch.exists("foo")
        >>>     is_garply_bar = image_patch.exists("garply bar")
        >>>     return sum_tensor([is_foo.confidence, is_garply_bar.confidence])
        """
        return self.find(object_name).confidence 

    def verify_property(self, object_name: str, visual_property: str) -> bool:
        """Returns float contains property. 
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        visual_property : str
            A string describing the simple visual property (e.g., color, shape, material) to be checked.

        Returns 
        ------
        tuple 
            tuple containing probability of object having visual property and average confidence
        Examples
        -------
        >>> # How likely is the letters have blue color?
        >>> def execute_command(image) -> str:
        >>>     image_patch = ImagePatch(image)
        >>>     confidences = []
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     confidences.append(letters_patches[0].confidence)
        >>>     properties = letters_patches[0].verify_property("letters", "blue")
        >>>     confidences.append(properties*letter_patches[0].confidence)
        >>>     return  sum_tensor(confidences)
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the foo gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     confidences = []
        >>>     foo_patches = image_patch.find("foo")
        >>>     # Question assumes one foo patch
        >>>     confidences.append(foo_patches[0].confidence)
        >>>     return  sum(confidences)
        """
        return best_text_match(self.cropped_image, option_list)

    
    def compute_depth(self):
        """Returns the median depth of the image crop
        Parameters
        ----------
        Returns
        -------
        float
            the median depth of the image crop

        Examples
        --------
        >>> # the bar furthest away
        >>> def execute_command(image)->ImagePatch:
        >>>     image_patch = ImagePatch(image)
        >>>     confidences = []
        >>>     bar_patches = image_patch.find("bar")
        >>>     bar_patches.sort(key=lambda bar: bar.compute_depth())
        >>>     confidences.append(bar_patches[-1].confidence)
        >>>     return bar_patches[-1], confidences
        """
        depth_map = compute_depth(self.cropped_image)
        return depth_map.median()

    def crop(self, left: int, lower: int, right: int, upper: int, confidence: float) -> ImagePatch:
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left, lower, right, upper : int
            The (left/lower/right/upper)most pixel of the cropped image.
        confidence: float
            Scores from model
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper, confidence)

    def overlaps_with(self, left, lower, right, upper):
        """Returns True if a crop with the given coordinates overlaps with this one,
        else False.
        Parameters
        ----------
        left, lower, right, upper : int
            the (left/lower/right/upper) border of the crop to be checked

        Returns
        -------
        float
            Probability a crop with the given coordinates overlaps with this one

        Examples
        --------
        >>> # How likely is black foo on top of the qux?
        >>> def execute_command(image) -> ImagePatch:
        >>>     image_patch = ImagePatch(image)
        >>>     qux_patches = image_patch.find("qux")
        >>>     qux_patch = qux_patches[0]
        >>>     answer = None
        >>>     confidences = []   
        >>>     foo_patches = image_patch.find("black foo")
        >>>     for foo in foo_patches:
        >>>         if foo.vertical_center > qux_patch.vertical_center:
        >>>             confidences.append(foo.confidence*(abs(foo.vertical_center-qux_patch.vertical_center)))
        >>>     return sum_tensor(confidences)
        """
        return sum_tensor(patches)

    

def best_image_match(list_patches: List[ImagePatch], content: List[str], return_index=False) -> Union[ImagePatch, int]:
    """Returns the patch most likely to contain the content.
    Parameters
    ----------
    list_patches : List[ImagePatch]
    content : List[str]
        the object of interest
    return_index : bool
        if True, returns the index of the patch most likely to contain the object

    Returns
    -------
    int
        Patch most likely to contain the object
    """
    return best_image_match(list_patches, content, return_index)


def distance(patch_a: ImagePatch, patch_b: ImagePatch) -> float:
    """
    Returns the distance between the edges of two ImagePatches. If the patches overlap, it returns a negative distance
    corresponding to the negative intersection over union.

    Parameters
    ----------
    patch_a : ImagePatch
    patch_b : ImagePatch

    Examples
    --------
    # Return the qux that is closest to the foo
    >>> def execute_command(image):
    >>>     image_patch = ImagePatch(image)
    >>>     qux_patches = image_patch.find('qux')
    >>>     foo_patches = image_patch.find('foo')
    >>>     confidences = []
    >>>     foo_patch = foo_patches[0]
    >>>     confidences.append(foo_patch.confidence)
    >>>     qux_patches.sort(key=lambda x: distance(x.vertical_center, foo_patch.vertical_center))
    >>>     confidences.append(qux_patches[0].confidence)
    >>>     return sum_tensor(confidences)
    """
    return distance(patch_a, patch_b)

def avg(values: list):
    return mean(values)
def sum_tensor(values:list):
    return sum(values)
Query: the person on the left is wearing red 
def execute_command(image):
    image_patch = ImagePatch(image)
    confidences = []
    person_patches = image_patch.find('person')
    person_patches.sort(key=lambda x:x.horizontal_center)
    confidences.append(person_patches[0].confidence)
    color_prediction = person_patches[0].verify_property("person","red")
    confidences.append(color_prediction*person_patches[0].confidence)
    return sum(confidences)
Query: the animal is running behind the trees 
def execute_command(image):
    image_patch = ImagePatch(image)
    confidences = []
    animal = image_patch.find('animal')
    running_animals = []
    for a in animal:
        confidences.append(a.verify_property('animal','running')*a.confidence)
    trees = image_patch.find('tree')
    for r_a in running_animals:
        for t in trees:
            confidences.append(abs(r_a.confidence*r_a.vertical_center-t.confidence*t.vertical_center))
    return sum(confidences)
Query: the soft couch is closer to the window than the table 
def execute_command(image):
    image_patch = ImagePatch(image)
    confidences = []
    couch_patches = image_patch.find('couch')
    for c in couch_patches:
        confidences.append(c.verify_property('couch','soft')*c.confidence)
    table = image_patch.find('table')
    window = image_patch.find('window')
    min_window_table = 1000
    min_window_couch = 1000 
    for w in window:
        for c in couch_patches:
            if distance(w.vertical_center,c.vertical_center) < min_window_couch:
                min_window_couch = distance(w.vertical_center,c.vertical_center) 
        for t in table_patches:
            if distance(w.vertical_center,t.vertical_center) < min_window_table:
                min_window_table = distance(w.vertical_center,t.vertical_center)
    confidences.append(abs(min_window_couch-min_window_table))
    return sum(confidences)

    

Write a function using Python and the ImagePatch class (above) that could be executed to provide an answer to the query. 

Consider the following guidelines:
- Use base Python (comparison, sorting) for basic logical operations, left/right/up/down, math, etc.
- All functions should return a float 
- Return sum of confidences as part of answer 

Query: INSERT_QUERY_HERE